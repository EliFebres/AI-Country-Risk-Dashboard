# backend/utils/data_fetching/fetch_metrics.py
import logging
import requests
import pandas as pd

from typing import List, Dict, Tuple, Mapping, Optional, Union, Any
from requests.exceptions import HTTPError, Timeout, ConnectionError, RequestException
from tenacity import (
    retry,
    wait_exponential_jitter,
    stop_after_attempt,
    retry_if_exception,
)

import backend.utils.constants as constants


# ---------------------------- Helpers --------------------------------- #
_RETRYABLE_STATUS = {429, 500, 502, 503, 504}
_DEFAULT_HEADERS = {
    "User-Agent": "AI-Country-Risk/1.0 (+https://github.com/EliFebres/AI-Country-Risk-Dashboard)"
}


def _is_retryable_exc(exc: BaseException) -> bool:
    """Retry on network/transient HTTP conditions only."""
    if isinstance(exc, (Timeout, ConnectionError)):
        return True
    if isinstance(exc, HTTPError):
        try:
            status = exc.response.status_code if exc.response is not None else None
        except Exception:
            status = None
        return status in _RETRYABLE_STATUS
    # Some libraries wrap HTTPError inside RequestException
    if isinstance(exc, RequestException):
        resp = getattr(exc, "response", None)
        status = getattr(resp, "status_code", None)
        return status in _RETRYABLE_STATUS or isinstance(exc, (Timeout, ConnectionError))
    return False


def _empty_return(indicator: str, tidy: bool) -> Union[List[Tuple[int, Optional[float]]], pd.Series]:
    """Return the correct 'empty' shape for wb_series depending on tidy flag."""
    if tidy:
        return pd.Series(dtype="float64", name=indicator)
    return []  # for descending list-of-pairs mode


# ----------------------------- Fetch one series ----------------------------- #
@retry(
    wait=wait_exponential_jitter(initial=1, max=30),
    stop=stop_after_attempt(5),
    retry=retry_if_exception(_is_retryable_exc),
    reraise=True,
)
def _wb_request(
    url: str,
    params: Dict[str, str],
    session: Optional[requests.Session],
) -> requests.Response:
    req = session or requests
    # Merge a UA header in a non-destructive way
    try:
        resp = req.get(url, params=params, headers=_DEFAULT_HEADERS, timeout=20)
    except RequestException as e:
        # Let tenacity decide if we retry
        raise e
    # If transient: raise so tenacity retries; if non-transient: we handle in caller.
    if resp.status_code in _RETRYABLE_STATUS:
        try:
            resp.raise_for_status()
        except HTTPError as e:
            e.response = resp  # ensure status is visible in retry predicate
            raise e
    return resp


def wb_series(
    code: str,
    indicator: str,
    *,
    start: Optional[int] = None,
    end:   Optional[int] = None,
    tidy: bool = False,
    session: Optional[requests.Session] = None,
) -> Union[List[Tuple[int, Optional[float]]], pd.Series]:
    """
    Fetch a World Bank indicator time series for a single country.

    Returns:
        list[(year, value | None)] in descending WB order when tidy=False,
        or pandas.Series (ascending years) when tidy=True.

    Robustness changes:
      - Retries only on transient statuses (429/5xx) and network errors.
      - Treats 200 with empty rows, 400/404 as 'no data' (empty), not as an error.
    """
    # Input validation
    assert isinstance(code, str) and code.strip(),  "`code` must be non-empty str"
    assert isinstance(indicator, str) and indicator.strip(), "`indicator` must be non-empty str"
    assert isinstance(tidy, bool), "`tidy` must be bool"
    if start is not None:
        assert isinstance(start, int), "`start` must be int"
    if end is not None:
        assert isinstance(end, int),   "`end` must be int"
    if start is not None and end is not None:
        assert start <= end, "`start` year must be ≤ `end` year"
    if session is not None:
        assert isinstance(session, requests.Session), "`session` must be requests.Session"

    norm_code = (code or "").strip().upper()

    if "?" in constants.WB_ENDPOINT:
        raise ValueError("WB_ENDPOINT should not include query parameters")

    url = constants.WB_ENDPOINT.format(code=norm_code, ind=indicator)
    params: Dict[str, str] = {"format": "json", "per_page": "1000"}
    if start is not None and end is not None:
        params["date"] = f"{start}:{end}"

    # Perform request with retry-on-transient
    try:
        resp = _wb_request(url, params, session)
    except RequestException as e:
        # If the exception was already filtered as non-retryable, we land here.
        logging.warning("WB network error for %s/%s: %s (skipping)", norm_code, indicator, e)
        return _empty_return(indicator, tidy)

    # Handle non-transient statuses gracefully (e.g., 400/404 → no data)
    if resp.status_code >= 400:
        if resp.status_code in (400, 404):
            logging.warning("WB %s for %s/%s (treating as empty)", resp.status_code, norm_code, indicator)
            return _empty_return(indicator, tidy)
        # Anything else 4xx that slipped through
        try:
            resp.raise_for_status()
        except HTTPError as e:
            logging.warning("WB HTTP %s for %s/%s: %s (skipping)", resp.status_code, norm_code, indicator, e)
            return _empty_return(indicator, tidy)

    # Parse payload
    try:
        payload = resp.json()
    except ValueError:
        logging.warning("WB invalid JSON for %s/%s (treating as empty)", norm_code, indicator)
        return _empty_return(indicator, tidy)

    if not isinstance(payload, list) or len(payload) < 2:
        logging.warning("WB unexpected payload for %s/%s: %s (treating as empty)", norm_code, indicator, payload)
        return _empty_return(indicator, tidy)

    rows = payload[1] or []  # WB returns [meta, rows]; rows can be None

    # Build list of (year, value) in WB default order (desc by year)
    series_pairs: List[Tuple[int, Optional[float]]] = []
    for item in rows:
        try:
            year = int(item.get("date"))
        except (TypeError, ValueError):
            continue
        val = item.get("value")
        series_pairs.append((year, float(val) if val is not None else None))

    # Local year filtering when only one bound supplied
    if start is not None and end is None:
        series_pairs = [(y, v) for y, v in series_pairs if y >= start]
    elif end is not None and start is None:
        series_pairs = [(y, v) for y, v in series_pairs if y <= end]

    if tidy:
        if not series_pairs:
            return pd.Series(dtype="float64", name=indicator)
        years = [y for (y, _) in series_pairs]
        vals  = [v for (_, v) in series_pairs]
        s = pd.Series(vals, index=years, name=indicator)
        return s.sort_index()

    # Default: return descending pairs (as WB provides)
    return series_pairs


# --------------------------- Multi-indicator panel --------------------------- #
def build_country_panel(
    code: str,
    indicators: Mapping[str, str],
    *,
    start: Optional[int] = None,
    end:   Optional[int] = None,
    tidy_fetch: bool = True,
) -> pd.DataFrame:
    """
    Assemble multiple World Bank indicators for one country into a year-indexed table.
    More resilient: reuses a single Session and tolerates missing indicators without failing the panel.
    """
    assert isinstance(code, str) and code.strip(), "`code` must be non-empty str"
    assert indicators, "`indicators` mapping must not be empty"
    assert all(isinstance(k, str) and k.strip() for k in indicators.keys()), \
        "all indicator names must be non-empty str"
    assert all(isinstance(v, str) and v.strip() for v in indicators.values()), \
        "all World-Bank codes must be non-empty str"
    if start is not None and end is not None:
        assert start <= end, "`start` year must be ≤ `end` year"
    assert isinstance(tidy_fetch, bool), "`tidy_fetch` must be bool"

    frames: List[pd.Series] = []
    # Reuse one session per country to avoid excess handshakes
    with requests.Session() as sess:
        sess.headers.update(_DEFAULT_HEADERS)
        for col, ind_code in indicators.items():
            try:
                if tidy_fetch:
                    s: Any = wb_series(code, ind_code, start=start, end=end, tidy=True, session=sess)
                    if isinstance(s, pd.Series):
                        s.name = col
                    else:
                        s = pd.Series(dtype="float64", name=col)
                else:
                    lst = wb_series(code, ind_code, start=start, end=end, tidy=False, session=sess)
                    if not lst:
                        s = pd.Series(dtype="float64", name=col)
                    else:
                        years, vals = zip(*lst)  # WB order is descending
                        s = pd.Series(list(vals)[::-1], index=list(years)[::-1], name=col)
            except RequestException as e:
                logging.warning("WB network error for %s/%s: %s (skipping)", code, ind_code, e)
                s = pd.Series(dtype="float64", name=col)
            except Exception as e:
                logging.warning("WB error for %s/%s: %s (skipping)", code, ind_code, e)
                s = pd.Series(dtype="float64", name=col)

            frames.append(s)

    if not frames:
        return pd.DataFrame()

    panel = pd.concat(frames, axis=1, sort=True)  # outer-join on year
    try:
        panel = panel.astype("float64")
    except Exception:
        pass
    return panel
